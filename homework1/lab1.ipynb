{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import os.path\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "\n",
    "import time\n",
    "import binascii\n",
    "import numpy as np\n",
    "from time import clock\n",
    "from random import randint, seed, choice, random\n",
    "import string\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "printedbodies = {}\n",
    "data=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class shingling  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shingling:\n",
    "    #global documents , printedbodies\n",
    "    d = {}\n",
    "\n",
    "    t = {}\n",
    "    docsAsShingleSets = {}\n",
    "\n",
    "    docNames = []\n",
    "\n",
    "    totalShingles = 0\n",
    "    shingleNo = 0\n",
    "    shingle_size=0\n",
    "    def __init__(self,documents):\n",
    "        i = 0\n",
    "        self.documents=documents\n",
    "        for value in self.documents:\n",
    "\n",
    "\n",
    "            # create a dictionary where key=docid and value=document text\n",
    "            self.d[i] = value\n",
    "            # split text into words\n",
    "            self.d[i] = re.sub(\"[^\\w]\", \" \", self.d[i]).split()\n",
    "\n",
    "            # remove rows with empty values from dictionary d\n",
    "            if self.d[i]:\n",
    "                i = i + 1\n",
    "            else:\n",
    "                del self.d[i]\n",
    "                del self.body[i]\n",
    "\n",
    "        # =============================================================================\n",
    "        #               Convert Documents To Sets of Shingles\n",
    "        # =============================================================================\n",
    "\n",
    "      \n",
    "        ######Ask user to give a value for k\n",
    "        while True:\n",
    "            try:\n",
    "                self.shingle_size = int(raw_input(\"Please enter k value for k-shingles: \"))\n",
    "            except ValueError:\n",
    "                print(\"Your input is not valid. Give a positive natural number > 0...\")\n",
    "                continue\n",
    "            if self.shingle_size <= 0:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "    def func_Shingling(self):\n",
    "        print \"Shingling articles...\"\n",
    "\n",
    "        t0 = time.time()\n",
    "        # loop through all the documents\n",
    "        for i in range(0, len(self.d)):\n",
    "\n",
    "            # Read all of the words (they are all on one line)\n",
    "            words = self.d[i]\n",
    "\n",
    "            # Retrieve the article ID\n",
    "            docID = i\n",
    "\n",
    "            # Maintain a list of all document IDs.\n",
    "            self.docNames.append(docID)\n",
    "\n",
    "            # 'shinglesInDoc' will hold all of the unique shingles present in the\n",
    "            # current document. If a shingle ID occurs multiple times in the document,\n",
    "            # it will only appear once in the set.\n",
    "\n",
    "            # keep word shingles\n",
    "            self.shinglesInDocWords = set()\n",
    "\n",
    "            # keep hashed shingles\n",
    "            self.shinglesInDocInts = set()\n",
    "\n",
    "            shingle = []\n",
    "            # For each word in the document...\n",
    "            for index in range(len(words) - self.shingle_size + 1):\n",
    "                # Construct the shingle text by combining k words together.\n",
    "                shingle = words[index:index + self.shingle_size]\n",
    "                shingle = ' '.join(shingle)\n",
    "\n",
    "                # Hash the shingle to a 32-bit integer.\n",
    "                crc = binascii.crc32(shingle) & 0xffffffff\n",
    "\n",
    "                if shingle not in self.shinglesInDocWords:\n",
    "                    self.shinglesInDocWords.add(shingle)\n",
    "                # Add the hash value to the list of shingles for the current document.\n",
    "                # Note that set objects will only add the value to the set if the set\n",
    "                # doesn't already contain it.\n",
    "\n",
    "                if crc not in self.shinglesInDocInts:\n",
    "                    self.shinglesInDocInts.add(crc)\n",
    "                    # Count the number of shingles across all documents.\n",
    "                    self.shingleNo = self.shingleNo + 1\n",
    "                else:\n",
    "                    del shingle\n",
    "                    index = index - 1\n",
    "\n",
    "            # Store the completed list of shingles for this document in the dictionary.\n",
    "            self.docsAsShingleSets[docID] = self.shinglesInDocInts\n",
    "\n",
    "        self.totalShingles = self.shingleNo\n",
    "\n",
    "        print 'Total Number of Shingles', self.shingleNo\n",
    "        # Report how long shingling took.\n",
    "        print '\\nShingling ' + str(len(self.docsAsShingleSets)) + ' docs took %.2f sec.' % (time.time() - t0)\n",
    "\n",
    "        print '\\nAverage shingles per doc: %.2f' % (self.shingleNo / len(self.docsAsShingleSets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minhashing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class MinHashing:\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    numHashes=0\n",
    "    numDocs=0\n",
    "   \n",
    "    signatures = []\n",
    "    def __init__(self):\n",
    "       \n",
    "       \n",
    "        ######Ask user to give a value for hash functions to be used\n",
    "        while True:\n",
    "            try:\n",
    "                self.numHashes = int(raw_input(\"\\nPlease enter how many hash functions you want to be used: \"))\n",
    "            except ValueError:\n",
    "                print(\"Your input is not valid. Give a positive natural number > 0...\")\n",
    "                continue\n",
    "            if self.numHashes <= 0:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        print '\\nGenerating random hash functions...'\n",
    "\n",
    "    # =============================================================================\n",
    "    #                 Generate MinHash Signatures\n",
    "    # =============================================================================\n",
    "  \n",
    "\n",
    "    \n",
    "\n",
    "    # https://www.codeproject.com/Articles/691200/Primality-test-algorithms-Prime-test-The-fastest-w\n",
    "    # check if integer n is a prime\n",
    "    # probabilistic method, much faster than usual priminality tests\n",
    "    def MillerRabinPrimalityTest(self,number):\n",
    "        '''\n",
    "        because the algorithm input is ODD number than if we get\n",
    "        even and it is the number 2 we return TRUE ( spcial case )\n",
    "        if we get the number 1 we return false and any other even\n",
    "        number we will return false.\n",
    "        '''\n",
    "        if number == 2:\n",
    "            return True\n",
    "        elif number == 1 or number % 2 == 0:\n",
    "            return False\n",
    "\n",
    "        ''' first we want to express n as : 2^s * r ( were r is odd ) '''\n",
    "\n",
    "        ''' the odd part of the number '''\n",
    "        oddPartOfNumber = number - 1\n",
    "\n",
    "        ''' The number of time that the number is divided by two '''\n",
    "        timesTwoDividNumber = 0\n",
    "\n",
    "        ''' while r is even divid by 2 to find the odd part '''\n",
    "        while oddPartOfNumber % 2 == 0:\n",
    "            oddPartOfNumber = oddPartOfNumber / 2\n",
    "            timesTwoDividNumber = timesTwoDividNumber + 1\n",
    "\n",
    "        '''\n",
    "        since there are number that are cases of \"strong liar\" we\n",
    "        need to check more then one number\n",
    "        '''\n",
    "        for time in range(3):\n",
    "\n",
    "            ''' choose \"Good\" random number '''\n",
    "            while True:\n",
    "                ''' Draw a RANDOM number in range of number ( Z_number )  '''\n",
    "                randomNumber = randint(2, number) - 1\n",
    "                if randomNumber != 0 and randomNumber != 1:\n",
    "                    break\n",
    "\n",
    "            ''' randomNumberWithPower = randomNumber^oddPartOfNumber mod number '''\n",
    "            print randomNumber, oddPartOfNumber, number\n",
    "            randomNumberWithPower = pow(randomNumber, oddPartOfNumber, number)\n",
    "\n",
    "            ''' if random number is not 1 and not -1 ( in mod n ) '''\n",
    "            if (randomNumberWithPower != 1) and (randomNumberWithPower != number - 1):\n",
    "                # number of iteration\n",
    "                iterationNumber = 1\n",
    "\n",
    "                ''' while we can squre the number and the squered number is not -1 mod number'''\n",
    "                while (iterationNumber <= timesTwoDividNumber - 1) and (randomNumberWithPower != number - 1):\n",
    "                    ''' squre the number '''\n",
    "                    randomNumberWithPower = pow(randomNumberWithPower, 2, number)\n",
    "\n",
    "                    # inc the number of iteration\n",
    "                    iterationNumber = iterationNumber + 1\n",
    "                '''\n",
    "                if x != -1 mod number then it because we did not found strong witnesses\n",
    "                hence 1 have more then two roots in mod n ==>\n",
    "                n is composite ==> return false for primality\n",
    "                '''\n",
    "                if (randomNumberWithPower != (number - 1)):\n",
    "                    return False\n",
    "\n",
    "        ''' well the number pass the tests ==> it is probably prime ==> return true for primality '''\n",
    "        return True\n",
    "    # Our random hash function will take the form of:\n",
    "    #   h(x) = (a*x + b) % c\n",
    "    # Where 'x' is the input value, 'a' and 'b' are random coefficients, and 'c' is\n",
    "    # a prime number just greater than shingleNo.\n",
    "\n",
    "    # Generate a list of 'k' random coefficients for the random hash functions,\n",
    "    # while ensuring that the same value does not appear multiple times in the\n",
    "    # list.\n",
    "    def pickRandomCoeffs(self, k, maxShingleID):\n",
    "        # Create a list of 'k' random values.\n",
    "        randList = []\n",
    "\n",
    "        while k > 0:\n",
    "            # Get a random shingle ID.\n",
    "            randIndex = randint(0, maxShingleID)\n",
    "\n",
    "            # Ensure that each random number is unique.\n",
    "            while randIndex in randList:\n",
    "                randIndex = randint(0, maxShingleID)\n",
    "\n",
    "                # Add the random number to the list.\n",
    "            randList.append(randIndex)\n",
    "            k = k - 1\n",
    "\n",
    "        return randList\n",
    "\n",
    "    def generatHash(self,docNames,shingleNo,docsAsShingleSets):\n",
    "        # Time this step.\n",
    "        t0 = time.time()\n",
    "        self.docNames=docNames\n",
    "        self.shingleNo=shingleNo\n",
    "        self.docsAsShingleSets= docsAsShingleSets\n",
    "        # Record the total number of shingles\n",
    "        i = 1\n",
    "        # find first prime which is higher than the total number of shingles\n",
    "        # print 'Total number of shingles = ', shingleNo\n",
    "        while not self.MillerRabinPrimalityTest(self.shingleNo + i):\n",
    "            i = i + 1\n",
    "        print 'Next prime = ', self.shingleNo + i\n",
    "\n",
    "        maxShingleID = self.shingleNo\n",
    "        nextPrime = self.shingleNo + i\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "        # For each of the 'numHashes' hash functions, generate a different coefficient 'a' and 'b'.\n",
    "        coeffA = self.pickRandomCoeffs(self.numHashes,maxShingleID)\n",
    "        coeffB = self.pickRandomCoeffs(self.numHashes,maxShingleID)\n",
    "\n",
    "        print '\\nGenerating MinHash signatures for all documents...'\n",
    "\n",
    "        # List of documents represented as signature vectors\n",
    "        \n",
    "\n",
    "        # Rather than generating a random permutation of all possible shingles,\n",
    "        # we'll just hash the IDs of the shingles that are *actually in the document*,\n",
    "        # then take the lowest resulting hash code value. This corresponds to the index\n",
    "        # of the first shingle that you would have encountered in the random order.\n",
    "        # For each document...\n",
    "        for docID in self.docNames:\n",
    "\n",
    "            # Get the shingle set for this document.\n",
    "            shingleIDSet = self.docsAsShingleSets[docID]\n",
    "\n",
    "            # The resulting minhash signature for this document.\n",
    "            signature = []\n",
    "\n",
    "            # For each of the random hash functions...\n",
    "            for i in range(0, self.numHashes):\n",
    "\n",
    "                # For each of the shingles actually in the document, calculate its hash code\n",
    "                # using hash function 'i'.\n",
    "\n",
    "                # Track the lowest hash ID seen. Initialize 'minHashCode' to be greater than\n",
    "                # the maximum possible value output by the hash.\n",
    "                minHashCode = nextPrime + 1\n",
    "\n",
    "                # For each shingle in the document...\n",
    "                for shingleID in shingleIDSet:\n",
    "                    # Evaluate the hash function.\n",
    "                    hashCode = (coeffA[i] * shingleID + coeffB[i]) % nextPrime\n",
    "\n",
    "                    # Track the lowest hash code seen.\n",
    "                    if hashCode < minHashCode:\n",
    "                        minHashCode = hashCode\n",
    "\n",
    "                # Add the smallest hash code value as component number 'i' of the signature.\n",
    "                signature.append(minHashCode)\n",
    "\n",
    "            # Store the MinHash signature for this document.\n",
    "            self.signatures.append(signature)\n",
    "\n",
    "        # Calculate the elapsed time (in seconds)\n",
    "        elapsed = (time.time() - t0)\n",
    "\n",
    "        print \"\\nGenerating MinHash signatures took %.2fsec\" % elapsed\n",
    "        self.numDocs = len(self.signatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CompareSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from decimal import *\n",
    "class CompareSets:\n",
    "    ######Ask user to choose a document\n",
    "    docid=0\n",
    "    neighbors=0\n",
    "    numDocs=0\n",
    "    fp = []\n",
    "    tp = []\n",
    "    def __init__(self,numDocs):\n",
    "        self.numDocs=numDocs\n",
    "        while True:\n",
    "            try:\n",
    "                self.docid = int(raw_input(\n",
    "                    \"Please enter the document id you are interested in. The valid document ids are 1 - \" + str(\n",
    "                        self.numDocs) + \": \"))\n",
    "            except ValueError:\n",
    "                print(\"Your input is not valid.\")\n",
    "                continue\n",
    "            if self.docid <= 0 or self.docid > self.numDocs:\n",
    "                print (\"Your input is out of the defined range...\")\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        ######Ask user to give desired number of neighbors\n",
    "        while True:\n",
    "            try:\n",
    "                self.neighbors = int(raw_input(\"Please enter the number of closest neighbors you want to find... \"))\n",
    "            except ValueError:\n",
    "                print(\"Your input is not valid.\")\n",
    "                continue\n",
    "            if self.neighbors <= 0:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "    # Define a function to map a 2D matrix coordinate into a 1D index.\n",
    "    def getTriangleIndex(self,i, j,docsAsShingleSets):\n",
    "        # If i == j that's an error.\n",
    "        if i == j:\n",
    "            sys.stderr.write(\"Can't access triangle matrix with i == j\")\n",
    "            sys.exit(1)\n",
    "        # If j < i just swap the values.\n",
    "        if j < i:\n",
    "            temp = i\n",
    "            i = j\n",
    "            j = temp\n",
    "\n",
    "        # Calculate the index within the triangular array.\n",
    "        # This fancy indexing scheme is taken from pg. 211 of:\n",
    "        # http://infolab.stanford.edu/~ullman/mmds/ch6.pdf\n",
    "        # But I adapted it for a 0-based index.\n",
    "        # Note: The division by two should not truncate, it\n",
    "        #       needs to be a float.\n",
    "        k = int(i * (len(docsAsShingleSets) - (i + 1) / 2.0) + j - i) - 1\n",
    "\n",
    "        return k\n",
    "\n",
    "    def JaccardSimilarities(self,docNames,shingleNo,docsAsShingleSets):\n",
    "        \n",
    "        \n",
    "        numElems = int(len(docsAsShingleSets) * (len(docsAsShingleSets) - 1) / 2)\n",
    "\n",
    "        # Initialize two empty lists to store the similarity values.\n",
    "        # 'JSim' will be for the actual Jaccard Similarity values.\n",
    "        # 'estJSim' will be for the estimated Jaccard Similarities found by comparing\n",
    "        # the MinHash signatures.\n",
    "        print numElems\n",
    "        JSim = np.zeros(numElems)#[0 for x in range(numElems)]\n",
    "       # estJSim = np.zeros(numElems)#[0 for x in range(numElems)]\n",
    "\n",
    "\n",
    "        # =============================================================================\n",
    "        #                 Calculate Jaccard Similarities\n",
    "        # =============================================================================\n",
    "        # In this section, we will directly calculate the Jaccard similarities by\n",
    "        # comparing the sets. This is included here to show how much slower it is than\n",
    "        # the MinHash approach.\n",
    "\n",
    "        # Calculating the Jaccard similarities gets really slow for large numbers\n",
    "        # of documents.\n",
    "       \n",
    "\n",
    "       \n",
    "\n",
    "        print \"\\nCalculating Jaccard Similarities of Shingles...\"\n",
    "\n",
    "        # Time the calculation.\n",
    "        t0 = time.time()\n",
    "\n",
    "        s0 = len(docsAsShingleSets[0])\n",
    "        # For every document pair...\n",
    "        i = self.docid\n",
    "\n",
    "        # Print progress every 100 documents.\n",
    "        if (i % 100) == 0:\n",
    "            print \"  (\" + str(i) + \" / \" + str(len(docsAsShingleSets)) + \")\"\n",
    "\n",
    "        # Retrieve the set of shingles for document i.\n",
    "        s1 = docsAsShingleSets[docNames[i]]\n",
    "        neighbors_of_given_documentSHINGLES = {}\n",
    "       \n",
    "\n",
    "        for j in range(0, len(docsAsShingleSets)):\n",
    "            if j != i:\n",
    "                # Retrieve the set of shingles for document j.\n",
    "                s2 = docsAsShingleSets[docNames[j]]\n",
    "\n",
    "                # Calculate and store the actual Jaccard similarity.\n",
    "                JSim[self.getTriangleIndex(i, j,docsAsShingleSets)] = (len(s1.intersection(s2)) / float(len(s1.union(s2))))\n",
    "                percsimilarity = JSim[self.getTriangleIndex(i, j,docsAsShingleSets)] * 100\n",
    "                if (percsimilarity > 0):\n",
    "                    # Print out the match and similarity values with pretty spacing.\n",
    "                    #print \"  %5s --> %5s   %.2f%s   \" % (docNames[i], docNames[j], percsimilarity, '%')\n",
    "                    neighbors_of_given_documentSHINGLES[j] = percsimilarity\n",
    "\n",
    "        sorted_neigborsSHINGLES = sorted(neighbors_of_given_documentSHINGLES.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        print 'Comparing Shingles ...'\n",
    "        print \"The \" + str(self.neighbors) + \" closest neighbors of document \" + str(docNames[i]) + \" are:\"\n",
    "        for i in range(0, self.neighbors):\n",
    "            if i >= len(sorted_neigborsSHINGLES):\n",
    "                break\n",
    "            self.tp.append(sorted_neigborsSHINGLES[i][0])\n",
    "            print \"Shingles of Document \" + str(sorted_neigborsSHINGLES[i][0]) + \" with Jaccard Similarity \" + str(\n",
    "                round(sorted_neigborsSHINGLES[i][1], 2)) + \"%\"\n",
    "\n",
    "            # Calculate the elapsed time (in seconds)\n",
    "        elapsed = (time.time() - t0)\n",
    "\n",
    "        print 'These are the True Positives, since no time saving assumptions were made while calculating the Jaccard similarity of shingles'\n",
    "        print \"\\nCalculating all Jaccard Similarities of Shingles Took %.2fsec\" % elapsed\n",
    "        print '\\nNote: In this section, we directly calculated the Jaccard similarities by comparing the shingle sets. This is included here to show how much slower it is than the MinHash and LSH approach.'\n",
    "        print '\\nMoreover, the similarities calculated above are the actual similarities of the documents, since there were no assumption made'\n",
    "\n",
    "        # shingleNo =  shingleNo + s0\n",
    "        # print 'number', shingleNo\n",
    "\n",
    "        # Delete the Jaccard Similarities, since it's a pretty big matrix.\n",
    "        del JSim\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CompareSignatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompareSignatures:\n",
    "    # =============================================================================\n",
    "    #                  Compare ALl Signatures & Display Similar Document Pairs\n",
    "    # =============================================================================\n",
    "    tpsig = 0\n",
    "    fpsig = 0\n",
    "\n",
    "    \n",
    "\n",
    "    threshold = 0\n",
    "    def __init__(self,signatures):\n",
    "        print 'Number of signatures', len(signatures)\n",
    "        # Count the true positives and false positives.\n",
    "\n",
    "        print '\\nNow we will calculate Jaccard Similarity between signatures'\n",
    "        print \"Values shown are the estimated Jaccard similarity\"\n",
    "    # Define a function to map a 2D matrix coordinate into a 1D index.\n",
    "    def getTriangleIndex(self,i, j,docsAsShingleSets):\n",
    "        # If i == j that's an error.\n",
    "        if i == j:\n",
    "            sys.stderr.write(\"Can't access triangle matrix with i == j\")\n",
    "            sys.exit(1)\n",
    "        # If j < i just swap the values.\n",
    "        if j < i:\n",
    "            temp = i\n",
    "            i = j\n",
    "            j = temp\n",
    "\n",
    "        # Calculate the index within the triangular array.\n",
    "        # This fancy indexing scheme is taken from pg. 211 of:\n",
    "        # http://infolab.stanford.edu/~ullman/mmds/ch6.pdf\n",
    "        # But I adapted it for a 0-based index.\n",
    "        # Note: The division by two should not truncate, it\n",
    "        #       needs to be a float.\n",
    "        k = int(i * (len(docsAsShingleSets) - (i + 1) / 2.0) + j - i) - 1\n",
    "\n",
    "        return k\n",
    "\n",
    "    def computefunct(self,docNames,docid,signatures,numDocs,numHashes,tp,docsAsShingleSets,neighbors):\n",
    "        t0 = time.time()\n",
    "        # For each of the document pairs...\n",
    "        # for i in range(1, numDocs-1):\n",
    "        i = docid\n",
    "        signature1 = signatures[i]\n",
    "\n",
    "        neighbors_of_given_documentSIGNATURES = {}\n",
    "        # Calculate the number of elements needed in our triangle matrix\n",
    "        numElems = int(len(docsAsShingleSets) * (len(docsAsShingleSets) - 1) / 2)\n",
    "        estJSim = np.zeros(numElems)#[0 for x in range(numElems)]\n",
    "        for j in range(0, numDocs):\n",
    "            if (i != j):\n",
    "                signature2 = signatures[j]\n",
    "                count = 0\n",
    "                # Count the number of positions in the minhash signature which are equal.\n",
    "                for k in range(0, numHashes):\n",
    "\n",
    "                    if (signature1[k] == signature2[k]):\n",
    "                        count = count + 1\n",
    "\n",
    "                # Record the percentage of positions which matched.\n",
    "                estJSim[self.getTriangleIndex(i, j,docsAsShingleSets)] = (count / float(numHashes))\n",
    "\n",
    "                # Retrieve the estimated similarity value for this pair.\n",
    "                # estJ = float(estJSim[getTriangleIndex(i, j)])\n",
    "\n",
    "                # If the similarity is above the threshold...\n",
    "                if float(estJSim[self.getTriangleIndex(i, j,docsAsShingleSets)]) > 0:\n",
    "\n",
    "                    # Calculate the actual Jaccard similarity for validation.\n",
    "                    s1 = set(signature1)\n",
    "                    s2 = set(signature2)\n",
    "\n",
    "                    J = len(s1.intersection(s2)) / float(len(s1.union(s2)))\n",
    "                    neighbors1 = []\n",
    "                    if (float(J) > self.threshold):\n",
    "                        percsimilarity = estJSim[self.getTriangleIndex(i, j,docsAsShingleSets)] * 100\n",
    "\n",
    "                        percJ = J * 100\n",
    "                        # Print out the match and similarity values with pretty spacing.\n",
    "                        # print \"  %5s --> %5s   %.2f%s \" % (docNames[i], docNames[j], percJ, '%')\n",
    "                        neighbors_of_given_documentSIGNATURES[j] = percJ\n",
    "\n",
    "        sorted_neigborsSIGNATURES = sorted(neighbors_of_given_documentSIGNATURES.items(), key=lambda x: x[1], reverse=True)\n",
    "        # print \"Sorted Neighbors Signatures\", sorted_neigbors, \"%\"\n",
    "\n",
    "        sigpos = []\n",
    "        print 'Comparing Signatures...'\n",
    "        print \"The \" + str(neighbors) + \" closest neighbors of document \" + str(docNames[i]) + \" are:\"\n",
    "        for i in range(0, neighbors):\n",
    "            if i >= len(sorted_neigborsSIGNATURES):\n",
    "                break\n",
    "            print \"Signatures of Document \" + str(sorted_neigborsSIGNATURES[i][0]) + \" with Jaccard Similarity \" + str(\n",
    "                round(sorted_neigborsSIGNATURES[i][1], 2)) + \"%\"\n",
    "            sigpos.append(sorted_neigborsSIGNATURES[i][0])\n",
    "\n",
    "        fpsig = neighbors - len(list(set(tp).intersection(sigpos)))\n",
    "        tpsig = neighbors - fpsig\n",
    "        elapsed = (time.time() - t0)\n",
    "        print '\\n', tpsig, '/', neighbors, 'True Positives and', fpsig, '/', neighbors, 'False Positives Produced While Comparing Signatures',\n",
    "\n",
    "        print \"\\nCalculating Jaccard Similarity of Signatures took %.2fsec\" % elapsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    threshold=0\n",
    "    tp=[]\n",
    "    docid=0\n",
    "    band_size=0\n",
    "    numHashes=0\n",
    "    \n",
    "    def __init__(self,numHashes,tp,docid):\n",
    "        self.tp=tp\n",
    "        self.docid=docid\n",
    "        self.numHashes=numHashes\n",
    "        while True:\n",
    "            try:\n",
    "                self.band_size = int(\n",
    "                    raw_input(\"\\nPlease enter the size of the band. Valid band rows are 1 - \" + str(self.numHashes) + \": \"))\n",
    "            except ValueError:\n",
    "                print(\"Your input is not valid.\")\n",
    "                continue\n",
    "            if self.band_size <= 0 or self.band_size > self.numHashes:\n",
    "                print (\"Your input is out of the defined range...\")\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "    def get_band_hashes(self,minhash_row, band_size):\n",
    "        band_hashes = []\n",
    "        for i in range(len(minhash_row)):\n",
    "            if i % band_size == 0:\n",
    "                if i > 0:\n",
    "                    band_hashes.append(band_hash)\n",
    "                band_hash = 0\n",
    "            band_hash += hash(minhash_row[i])\n",
    "        return band_hashes\n",
    "    def get_similar_docs(self,neighbors,docs, shingles, threshold, n_hashes, band_size,printedbodies, collectIndexes=True):\n",
    "        t0 = time.time()\n",
    "        lshsignatures = {}\n",
    "        hash_bands = {}\n",
    "        neighbors_of_given_documentLSH = {}\n",
    "        random_strings = [str(random()) for _ in range(n_hashes)]\n",
    "        docNum = 0\n",
    "\n",
    "        # for key, value in t.iteritems():\n",
    "        #    temp = [key, doc]\n",
    "        #   tlist.append(temp)\n",
    "        w = 0\n",
    "        # for doc in docs.iteritems():\n",
    "        for doc in docs:\n",
    "\n",
    "            lshsignatures[w] = doc\n",
    "            # shingles = generate_shingles(doc, shingle_size)\n",
    "            # print 'doc', doc\n",
    "            # shingles = doc\n",
    "\n",
    "            minhash_row = doc\n",
    "            # print 'minhash_row', minhash_row, type(minhash_row)\n",
    "            band_hashes = self.get_band_hashes(minhash_row, band_size)\n",
    "            # print 'band_hashes', band_hashes\n",
    "            w = w + 1\n",
    "            docMember = docNum if collectIndexes else doc\n",
    "            for i in range(len(band_hashes)):\n",
    "                if i not in hash_bands:\n",
    "                    hash_bands[i] = {}\n",
    "                if band_hashes[i] not in hash_bands[i]:\n",
    "                    hash_bands[i][band_hashes[i]] = [docMember]\n",
    "                else:\n",
    "                    hash_bands[i][band_hashes[i]].append(docMember)\n",
    "            docNum += 1\n",
    "\n",
    "        similar_docs = set()\n",
    "        similarity1 = []\n",
    "        noPairs = 0\n",
    "        print 'Comparing Signatures Found in the Same Buckets During LSH ...'\n",
    "        # print \"\\n    Jaccard similarity After LSH\\n\"\n",
    "        # print \"    Pairs          Similarity\"\n",
    "        samebucketLSH = []\n",
    "        samebucketcnt = 0\n",
    "        for i in hash_bands:\n",
    "            for hash_num in hash_bands[i]:\n",
    "                if len(hash_bands[i][hash_num]) > 1:\n",
    "                    for pair in itertools.combinations(hash_bands[i][hash_num], r=2):\n",
    "                        if pair not in similar_docs:\n",
    "                            similar_docs.add(pair)\n",
    "                            if pair[0] == self.docid and pair[1] != self.docid:\n",
    "\n",
    "                                s1 = set(lshsignatures[pair[0]])\n",
    "                                s2 = set(lshsignatures[pair[1]])\n",
    "\n",
    "                                sim = len(s1.intersection(s2)) / float(len(s1.union(s2)))\n",
    "                                if (float(sim) > threshold):\n",
    "                                    percsim = sim * 100\n",
    "                                    # print  \"  %5s --> %5s   %.2f%s\" % (pair[0], pair[1], percsim,'%')\n",
    "                                    noPairs = noPairs + 1\n",
    "                                    # return similar texts\n",
    "\n",
    "                                    # print 'TEXT WITH ID: ', pair[0], '\\n AND BODY: ', body[pair[0]], '\\n IS ', sim*100, '% SIMILAR TO', '\\n TEXT WITH ID: ', pair[1], '\\n AND BODY: ', body[pair[1]], '\\n'\n",
    "                                else:\n",
    "                                    percsim = 0\n",
    "                                neighbors_of_given_documentLSH[pair[1]] = percsim\n",
    "                                samebucketLSH.append(pair[1])\n",
    "                                samebucketcnt = samebucketcnt + 1\n",
    "                                elapsed = (time.time() - t0)\n",
    "\n",
    "        print 'Number of false positives while comparing signatures which were found in the same bucket',\n",
    "        sorted_neigborsLSH = sorted(neighbors_of_given_documentLSH.items(), key=lambda x: x[1], reverse=True)\n",
    "        # print \"Sorted Neighbors Signatures\", sorted_neigbors, \"%\"\n",
    "\n",
    "        lshpos = []\n",
    "        print 'Comparing Signatures Found in the Same Bucket During LSH...'\n",
    "        print \"The \" + str(neighbors) + \" closest neighbors of document \" + str(self.docid) + \" are:\"\n",
    "        for i in range(0, neighbors):\n",
    "            if i >= len(sorted_neigborsLSH):\n",
    "                break\n",
    "            if sorted_neigborsLSH[i][1] > 0:\n",
    "                print \"\\nChosen Signatures (After LSH) of Document \" + str(sorted_neigborsLSH[i][0]) + \" with Jaccard Similarity \" + str(round(sorted_neigborsLSH[i][1], 2)) + \"%\"\n",
    "               # print \"\\nBody of document \" + str(sorted_neigborsLSH[i][0]) + \"\\n\" + str(printedbodies[sorted_neigborsLSH[i][0]])\n",
    "                lshpos.append(sorted_neigborsLSH[i][0])\n",
    "\n",
    "        neighborsfplsh = neighbors - len(list(set(self.tp).intersection(lshpos)))\n",
    "        neighborstplsh = neighbors - neighborsfplsh\n",
    "        # totalfplsh =\n",
    "        totaltplsh = len(list(set(self.tp).intersection(samebucketLSH)))\n",
    "        totalfplsh = samebucketcnt - totaltplsh\n",
    "\n",
    "        print '\\nEvaluating the', neighbors, 'neighbors produced by LSH...'\n",
    "        print neighborstplsh, 'out of', neighbors, 'TP and', neighborsfplsh, 'out of', neighbors, 'FP'\n",
    "        print '\\nEvaluating the', samebucketcnt, 'pairs which fell in the same bucket...'\n",
    "\n",
    "        if samebucketcnt > 0:\n",
    "            prctpLSH = round((totaltplsh / float(samebucketcnt)) * 100, 2)\n",
    "            prcfpLSH = 100 - prctpLSH\n",
    "            print totaltplsh, 'out of', samebucketcnt, 'documents which fell in the same bucket are TP', prctpLSH, '%'\n",
    "            print totalfplsh, 'out of', samebucketcnt, 'documents which fell in the same bucket are FP', prcfpLSH, '%'\n",
    "        else:\n",
    "            print totaltplsh, 'out of', samebucketcnt, 'documents which fell in the same bucket are TP'\n",
    "            print totalfplsh, 'out of', samebucketcnt, 'documents which fell in the same bucket are FP'\n",
    "\n",
    "        return similar_docs\n",
    "\n",
    "\n",
    "    def computefunt(self,neighbors,signatures,docsAsShingleSets,printedbodies,threshold):\n",
    "        t0 = time.time()\n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "        n_hashes = self.numHashes\n",
    "\n",
    "        n_similar_docs = 2\n",
    "        seed(42)\n",
    "\n",
    "        finalshingles = docsAsShingleSets\n",
    "\n",
    "        similar_docs = self.get_similar_docs(neighbors,signatures, finalshingles, threshold, n_hashes, self.band_size,printedbodies, collectIndexes=True)\n",
    "\n",
    "        print '\\nLocality Sensitive Hashing ' + str(len(signatures)) + ' docs took %.2f sec.' % (time.time() - t0)\n",
    "\n",
    "\n",
    "        r = float(n_hashes / self.band_size)\n",
    "        similarity = (1 / r) ** (1 / float(self.band_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading and cleaning file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile():\n",
    "    global data\n",
    "    print ('Reading files')\n",
    "    print ('Please wait...')\n",
    "    t0 = time.time()\n",
    "    data=''\n",
    "   \n",
    "\n",
    "    for file in os.listdir(\"data1/\"):\n",
    "        if file.endswith(\".sgm\"):\n",
    "            filename = os.path.join(\"data1\", file)\n",
    "\n",
    "            f = open(filename, 'r')\n",
    "            data = data + f.read()\n",
    "\n",
    "    print ('Reading data took %.2f sec.' % (time.time() - t0))\n",
    "\n",
    "def preprocessing():\n",
    "    global documents , printedbodies\n",
    "    print ('Transforming data...')\n",
    "    t0 = time.time()\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    bodies = soup.findAll('body')\n",
    "    i = 0\n",
    "    for body in bodies:\n",
    "        printedbodies[i] = body\n",
    "        documents.append(\n",
    "             re.sub(' +', ' ', str(body).replace(\"<body>\", \"\").replace(\"</body>\", \"\").translate(None, string.punctuation)\n",
    "               .replace(\"\u0003\", \"\").replace(\"\\n\", \" \").lower()))\n",
    "        i = i + 1\n",
    "\n",
    "    print ('Transforming data took %.2f sec.' % (time.time() - t0))\n",
    "\n",
    "    print ('The number of documents read was: ' + str(len(documents)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files\n",
      "Please wait...\n",
      "Reading data took 0.12 sec.\n",
      "Transforming data...\n",
      "Transforming data took 14.78 sec.\n",
      "The number of documents read was: 13646\n",
      "Please enter k value for k-shingles: 3\n",
      "Shingling articles...\n",
      "Total Number of Shingles 1770789\n",
      "\n",
      "Shingling 13646 docs took 2.26 sec.\n",
      "\n",
      "Average shingles per doc: 129.00\n",
      "\n",
      "Please enter how many hash functions you want to be used: 50\n",
      "\n",
      "Generating random hash functions...\n",
      "823828 885395 1770791\n",
      "711124 221349 1770793\n",
      "1440131 885397 1770795\n",
      "1578360 442699 1770797\n",
      "1282072 885399 1770799\n",
      "507413 885399 1770799\n",
      "747001 885399 1770799\n",
      "Next prime =  1770799\n",
      "\n",
      "Generating MinHash signatures for all documents...\n",
      "\n",
      "Generating MinHash signatures took 26.11sec\n",
      "Please enter the document id you are interested in. The valid document ids are 1 - 13646: 211\n",
      "Please enter the number of closest neighbors you want to find... 5\n",
      "93099835\n",
      "\n",
      "Calculating Jaccard Similarities of Shingles...\n",
      "Comparing Shingles ...\n",
      "The 5 closest neighbors of document 211 are:\n",
      "Shingles of Document 221 with Jaccard Similarity 100.0%\n",
      "Shingles of Document 325 with Jaccard Similarity 91.95%\n",
      "Shingles of Document 7932 with Jaccard Similarity 2.33%\n",
      "Shingles of Document 328 with Jaccard Similarity 1.86%\n",
      "Shingles of Document 250 with Jaccard Similarity 1.83%\n",
      "These are the True Positives, since no time saving assumptions were made while calculating the Jaccard similarity of shingles\n",
      "\n",
      "Calculating all Jaccard Similarities of Shingles Took 0.28sec\n",
      "\n",
      "Note: In this section, we directly calculated the Jaccard similarities by comparing the shingle sets. This is included here to show how much slower it is than the MinHash and LSH approach.\n",
      "\n",
      "Moreover, the similarities calculated above are the actual similarities of the documents, since there were no assumption made\n",
      "Number of signatures 13646\n",
      "\n",
      "Now we will calculate Jaccard Similarity between signatures\n",
      "Values shown are the estimated Jaccard similarity\n",
      "Comparing Signatures...\n",
      "The 5 closest neighbors of document 211 are:\n",
      "Signatures of Document 221 with Jaccard Similarity 100.0%\n",
      "Signatures of Document 325 with Jaccard Similarity 84.62%\n",
      "Signatures of Document 294 with Jaccard Similarity 3.16%\n",
      "Signatures of Document 1593 with Jaccard Similarity 2.11%\n",
      "Signatures of Document 13534 with Jaccard Similarity 2.11%\n",
      "\n",
      "2 / 5 True Positives and 3 / 5 False Positives Produced While Comparing Signatures \n",
      "Calculating Jaccard Similarity of Signatures took 0.08sec\n",
      "\n",
      "Please enter the size of the band. Valid band rows are 1 - 50: 5\n",
      "Comparing Signatures Found in the Same Buckets During LSH ...\n",
      "Number of false positives while comparing signatures which were found in the same bucket Comparing Signatures Found in the Same Bucket During LSH...\n",
      "The 5 closest neighbors of document 211 are:\n",
      "\n",
      "Chosen Signatures (After LSH) of Document 221 with Jaccard Similarity 100.0%\n",
      "\n",
      "Chosen Signatures (After LSH) of Document 325 with Jaccard Similarity 84.62%\n",
      "\n",
      "Evaluating the 5 neighbors produced by LSH...\n",
      "2 out of 5 TP and 3 out of 5 FP\n",
      "\n",
      "Evaluating the 3 pairs which fell in the same bucket...\n",
      "2 out of 3 documents which fell in the same bucket are TP 66.67 %\n",
      "1 out of 3 documents which fell in the same bucket are FP 33.33 %\n",
      "\n",
      "Locality Sensitive Hashing 13646 docs took 0.90 sec.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    global documents , printedbodies\n",
    "    \n",
    "    readfile()\n",
    "    \n",
    "    preprocessing()\n",
    "    single=Shingling(documents)\n",
    "    single.func_Shingling()\n",
    "    minhash=MinHashing()\n",
    "    minhash.generatHash(single.docNames,single.shingleNo,single.docsAsShingleSets)\n",
    "    compareSets=CompareSets(minhash.numDocs)\n",
    "    compareSets.JaccardSimilarities(single.docNames,single.shingleNo,single.docsAsShingleSets)\n",
    "    compareSignatures=CompareSignatures(minhash.signatures)\n",
    "    compareSignatures.computefunct(single.docNames,compareSets.docid,minhash.signatures,minhash.numDocs,minhash.numHashes,compareSets.tp,single.docsAsShingleSets,compareSets.neighbors)\n",
    "    lsh=LSH(minhash.numHashes,compareSets.tp,compareSets.docid)\n",
    "    lsh.computefunt(compareSets.neighbors,minhash.signatures,single.docsAsShingleSets,printedbodies,0)\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
